# -*- coding: utf-8 -*-
"""Mi primera red con numpy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sKhjFz_yYdZJHeqPP1EcFV5pcRo_kSdo
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_gaussian_quantiles

N = 1000
gaussian_quantiles = make_gaussian_quantiles(mean=None, 
                        cov = 0.1,
                        n_samples=N,
                        n_features=2,
                        n_classes=2,
                        shuffle=True,
                        random_state=None)

X, Y= gaussian_quantiles

Y = Y[:, np.newaxis]

plt.scatter(X[:,0], X[:,1], c=Y[:,0], s=40, cmap=plt.cm.Spectral)

"""Funciones de activacion"""

def sigmoid(x, derivate = False):
    if derivate:
      return np.exp(-x)/((np.exp(-x)+1)**2)
    else:
      return 1/(1+np.exp(-x))
  
def relu(x, derivate=False):
  if derivate:
    x[x<=0]=0
    x[x>0]=1
    return x
  else:
    return np.maximum(0,x)

"""Funciñon de pérdida"""

def mse(y, y_hat, derivate=False):
  if derivate:
    return (y_hat - y)
  else:
    return np.mean((y_hat-y)**2)

def initialize_parameters_deep(layers_dim):
  parameters = {}
  L = len (layers_dim)
  for l in range(0,L-1):
    parameters['W'+str(l+1)] = (np.random.rand(layers_dim[l],layers_dim[l+1]) * 2) -1
    parameters['b'+str(l+1)] = (np.random.rand(1,layers_dim[l+1]) * 2) -1
  return parameters

layers_dim = [2,4,8,1]
params = initialize_parameters_deep(layers_dim)

params

params['W1'].shape

np.matmul(X, params['W1']).shape

def train(x_data,lr,params,training=True):
#Fordward
  params['A0'] = x_data

  params['Z1'] = np.matmul(params['A0'], params['W1']) + params['b1']
  params['A1'] = relu(params['Z1'])

  params['Z2'] = np.matmul(params['A1'], params['W2']) + params['b2']
  params['A2'] = relu(params['Z2'])

  params['Z3'] = np.matmul(params['A2'], params['W3']) + params['b3']
  params['A3'] = sigmoid(params['Z3'])

  output = params['A3']

  #Backpropagation
  params['dZ3'] = mse(Y,output, True) * sigmoid(params['A3'], True)
  params['dW3'] = np.matmul(params['A2'].T, params['dZ3'])

  params['dZ2'] = np.matmul(params['dZ3'], params['W3'].T) * relu(params['A2'], True)
  params['dW2'] = np.matmul(params['A1'].T, params['dZ2'])

  params['dZ1'] = np.matmul(params['dZ2'], params['W2'].T) * relu(params['A1'], True)
  params['dW1'] = np.matmul(params['A0'].T, params['dZ1'])

  #Gradient descent
  params['W3'] = params['W3'] - params['dW3'] * lr 
  params['b3'] = params['b3'] - (np.means(params['Z3'], axis=0, kepdims=True)) * lr 

  params['W2'] = params['W2'] - params['dW2'] * lr 
  params['b2'] = params['b2'] - (np.means(params['Z2'], axis=0, kepdims=True)) * lr 

  params['W1'] = params['W1'] - params['dW1'] * lr 
  params['b1'] = params['b1'] - (np.means(params['Z1'], axis=0, kepdims=True)) * lr 

  return output

output.shape